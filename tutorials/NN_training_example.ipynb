{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4245cd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dnngior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938ab8b5",
   "metadata": {},
   "source": [
    "Load dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297119a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dnngior import NN_Trainer\n",
    "from dnngior.reaction_class import Reaction as rc\n",
    "path = Path.cwd()\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492bd991",
   "metadata": {},
   "source": [
    "### Generating reaction presence dataframe\n",
    "\n",
    "To prepare the training data we need to determine the reactions present in your training metabolic models. This means that we need generate a list of possible reactions found in your training data, which will serve as the reaction keys. We can then determine for every draft training models which of these reactions are present and create a binary list of reactions presences. We will end up with a binary array with on one axis the different reactions and on the other every model in the training data. \n",
    "\n",
    "We will use the class we build but you can use any module to load metabolic models or extract the reaction sets in another way, the key is to end up with a binary array of reaction presences. If you already have this, this step can be skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b12c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to training models\n",
    "\n",
    "model_path =  ''\n",
    "\n",
    "#output path training data\n",
    "\n",
    "output_path = ''\n",
    "\n",
    "#list of model-ids of draft-models\n",
    "paths  = os.listdir(model_path)\n",
    "model_ids = []\n",
    "for filename in paths:\n",
    "    model_ids.append(filename[:-5])\n",
    "n_models = len(model_ids)\n",
    "dic = {}\n",
    "rxn = []\n",
    "for file_path, model_id in zip(paths,model_ids):\n",
    "    print(model_id)\n",
    "    model = rc(model = os.path.join(model_path, file_path))\n",
    "    rs = set(model.reactions)\n",
    "    dic[model_id]=rs\n",
    "    \n",
    "    #generate a list of all possible reactions\n",
    "    for i in list(rs):\n",
    "         if i not in rxn:\n",
    "             rxn.append(i)\n",
    "\n",
    "n_reactions = len(rxn)\n",
    "\n",
    "reaction_df=pd.DataFrame(index=rxn, columns=model_ids)\n",
    "for key, value in dic.items():\n",
    "    a = []\n",
    "    for i in rxn:\n",
    "        if i in value:\n",
    "            a.append(1)\n",
    "        else:\n",
    "            a.append(0)\n",
    "    reaction_df[key]=a\n",
    "\n",
    "#saving to pandas file\n",
    "reaction_df.to_csv(output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c18a85d",
   "metadata": {},
   "source": [
    "### Training the Neural Network\n",
    "\n",
    "The easiest way to train the network requires providing a pandas dataframe where the index are the reaction keys and the columns the different training examples (see above). You can also provide a numpy array and the reaction keys as a separate list. The function will return a NN_predictor object to be used immediately, but it will also save it at output_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47130ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in a small training sample\n",
    "NN_folder = os.path.join(path,'docs', 'NN')\n",
    "data_path = os.path.join(NN_folder, 'Sample_reaction_presence.csv')\n",
    "data = pd.read_csv(data_path, index_col=0)\n",
    "\n",
    "#set save path\n",
    "save_path = os.path.join(NN_folder, 'example.npz')\n",
    "\n",
    "#Train the network\n",
    "NN_example = NN_Trainer.train(data=data, modeltype='ModelSEED',output_path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63bb24d",
   "metadata": {},
   "source": [
    "The function will return a object of the predictor class (NN_predictor) containing the network, the reaction keys and modeltype. By default the network in this object is not a full tensorflow object but rather an array of the weights and biases of the different layers. It can still be used to make predictions while being less memory intensive by using matrix multiplication:\n",
    "\n",
    "        a = input\n",
    "        for layer in self.network:\n",
    "            a = a.clip(0)\n",
    "            a = ((a @ layer[0]) + layer[1])\n",
    "        prediction =  1 / (1 + np.exp(-a))#sigmoid(a)\n",
    "        \n",
    "Which is build into the NN_Predictor class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1038650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The weights of the first layer network: \\n{}\".format(NN_example.network[0][0][:3,:3]))\n",
    "print(\"The bias of the first layer network: \\n{}\".format(NN_example.network[0][1][:3]))\n",
    "print(\"The rxn_keys: \\n{}\".format(NN_example.rxn_keys.values))\n",
    "print(\"The Modeltype: {}\".format(NN_example.modeltype))\n",
    "\n",
    "test_input = data.iloc[:,:3]\n",
    "p = NN_example.predict(test)\n",
    "print(\"Prediction: \\n{}\".format(np.round(p,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe06375d",
   "metadata": {},
   "source": [
    "### Changing feature generation parameters\n",
    "\n",
    "Basically you now know how to train networks but there are many additional changes you want to make during training. \n",
    "\n",
    "During training the function will automatically generate the training dataset. You can change several parameters for the generation of the feature:\n",
    "\n",
    "1. You can change the number of times each training model is used (nuplo).\n",
    "2. You can change the range of deletion percentages (min_for to max_for) which will be removed in equal sized steps based on the number of replicates. \n",
    "3. You can weigh the deletion of certain reactions (del_p). \n",
    "4. You can add false reactions (min_con and max_con) in addition to removing during training*\n",
    "\n",
    "*Note: we do not currently use this and it will not work with the masking of input reactions as the mask does not differentiate between contamination and real reactions.\n",
    "\n",
    "In the following example we set nuplo to 5 instead of 30, and we vary deletion between 0.05 and 0.35. We also dont have to keep saving them, so we can set save=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5b5c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = NN_Trainer.train(data=data, nuplo=5, min_for=0.05, max_for=0.35, modeltype='ModelSEED',save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c4d222",
   "metadata": {},
   "source": [
    "By default the network will asume that your input (the data without deletions) should be what the network tries to predict. Alternatively, you can provide labels (the full set of reactions) for the network to try and predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43494b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_labels = data.copy()\n",
    "np.random.shuffle(np.asarray(special_labels))\n",
    "special_labels.shape\n",
    "data.shape\n",
    "network = NN_Trainer.train(data=data, labels=special_labels, modeltype='ModelSEED',save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb9471b",
   "metadata": {},
   "source": [
    "Finally, you can rely on the default parameters to define the network which we optimised for our usecase, but for optimal perfomance on different datasets, you might want to change the hyperparameters (dropout, batch size), the architecture (nnodes, nlayers) or bias of predicted classes (bias0). You can also disable the masking of input positions during loss calculation (maskI=False). You can also provide a validation split which will set apart a part of your input data during training and calculate scores after to validate your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9a387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = NN_Trainer.train(data=data, dropout=0.2,b_size=42,nnodes = 420, nlayers=3, bias_0=0.42, maskI=False, validation_split=0.2, modeltype='ModelSEED',save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8144d0a2",
   "metadata": {},
   "source": [
    "### Tensorflow object\n",
    "\n",
    "By default the function returns a class with the simplified network but you very well might want instead the full Tensorflow network. To do this you can set return_full_network = True, which will change the NN_predictor to contain a Tensorflow network instead. If you want to save this different class you can change the file extension to .h5.\n",
    "\n",
    "If you set return_history = True it will also return the history of training for optimisation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59319dbf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_path = os.path.join(NN_folder, 'example.h5')\n",
    "NN_tensorflow, history = NN_Trainer.train(data=data, return_full_network=True, modeltype='ModelSEED', output_path=save_path, return_history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df9ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_tensorflow.network.summary()\n",
    "NN_tensorflow.network.predict(test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a041ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfcob",
   "language": "python",
   "name": "tfcob"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
